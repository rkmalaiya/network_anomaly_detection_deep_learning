{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:11.424686Z",
     "start_time": "2017-06-23T17:37:11.009471Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:11.996818Z",
     "start_time": "2017-06-23T17:37:11.426091Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train__2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    kdd_test__2labels = pd.read_pickle(\"dataset/kdd_test__2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train__5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:12.003910Z",
     "start_time": "2017-06-23T17:37:11.998445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25192, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:12.009947Z",
     "start_time": "2017-06-23T17:37:12.005596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:12.431235Z",
     "start_time": "2017-06-23T17:37:12.011285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97509982675167528"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Normal','is_Attack']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "    \n",
    "    x_test__input = dataset.kdd_test__2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test_ = dataset.kdd_test__2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "    x_test_ = ss.transform(x_test__input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "    y_test_ = y_test_.values\n",
    "\n",
    "    \n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:14.176523Z",
     "start_time": "2017-06-23T17:37:12.432977Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import basic_rnn_seq2seq\n",
    "from tensorflow.contrib.rnn import RNNCell, LSTMCell, MultiRNNCell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:14.431445Z",
     "start_time": "2017-06-23T17:37:14.178157Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 122\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x_input = tf.placeholder(\"float\", shape=[None, 1, input_dim])\n",
    "            self.y_input_ = tf.placeholder(\"float\", shape=[None, 1, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "            self.x_list = tf.unstack(self.x_input, axis= 1)\n",
    "            self.y_list_ = tf.unstack(self.y_input_, axis = 1)\n",
    "            self.y_ = self.y_list_[0]\n",
    "            \n",
    "            #GO = tf.fill((tf.shape(self.x)[0], 1), 0.5)\n",
    "            \n",
    "            #y_with_GO = tf.stack([self.y_, GO])\n",
    "            \n",
    "        with tf.variable_scope(\"lstm\"):\n",
    "            multi_cell = MultiRNNCell([LSTMCell(input_dim) for i in range(hidden_layers)] )\n",
    "            \n",
    "            self.y, states = basic_rnn_seq2seq(self.x_list, self.y_list_, multi_cell)\n",
    "            #self.y = tf.slice(self.y, [0, 0], [-1,2])\n",
    "            \n",
    "            #self.out = tf.squeeze(self.y)\n",
    "            \n",
    "            #self.y = tf.layers.dense(self.y[0], classes, activation = None)\n",
    "            \n",
    "            self.y = tf.slice(self.y[0], [0, 0], [-1,2])\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            self.regularized_loss = tf.losses.mean_squared_error(self.y_, self.y)\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T00:59:00.684124Z",
     "start_time": "2017-06-01T00:58:59.843181Z"
    }
   },
   "source": [
    "batch_iterations = 200\n",
    "\n",
    "x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "for i in batch_indices:\n",
    "    print(x_train[i,np.newaxis,:])\n",
    "    print(y_train[i,np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:14.716800Z",
     "start_time": "2017-06-23T17:37:14.433312Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'test_score_20', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "\n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_lstm_nsl_kdd-orig-/hidden layers_{}_features count_{}\".format(h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1})\n",
    "            \n",
    "            print(\"Initial Accuracy, before training: {}\".format(accuracy))\n",
    "            \n",
    "            for c, lr in enumerate(lrs):\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.1)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        _, train_loss = sess.run([net.train_op, net.regularized_loss], #net.summary_op\n",
    "                                                              feed_dict={net.x_input: x_train[i,np.newaxis,:], \n",
    "                                                                         net.y_input_: y_train[i,np.newaxis,:], \n",
    "                                                                         net.keep_prob:1, net.lr:lr})\n",
    "                        #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                        if(train_loss > 1e9):\n",
    "                            print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "\n",
    "\n",
    "                    valid_accuracy,valid_loss = sess.run([net.tf_accuracy, net.regularized_loss], #net.summary_op \n",
    "                                                          feed_dict={net.x_input: x_valid[:,np.newaxis,:], \n",
    "                                                                     net.y_input_: y_valid[:,np.newaxis,:], \n",
    "                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "\n",
    "\n",
    "                    accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "                    \n",
    "                    accuracy_, pred_value_, actual_value_, y_pred_ = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test_[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test_[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Train Accuracy: {:.6f} | Test Accuracy: {:.6f}, {:.6f}\".format(epoch, train_loss, valid_accuracy, accuracy, accuracy_))\n",
    "\n",
    "                    if accuracy > Train.best_acc_global:\n",
    "                                Train.best_acc_global = accuracy\n",
    "                                Train.pred_value = pred_value\n",
    "                                Train.actual_value = actual_value\n",
    "                                Train.pred_value_ = pred_value_\n",
    "                                Train.actual_value_ = actual_value_\n",
    "                                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if accuracy > Train.best_acc:\n",
    "\n",
    "                        #net.saver.save(sess, \"dataset/tf_vae_only_nsl_kdd_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "                        #curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                        #Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                        Train.best_acc = accuracy\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_lstm_nsl_kdd-orig-/hidden layers_{}_features count_{}/model\"\n",
    "                                       .format(h,f), \n",
    "                                       global_step = epoch, \n",
    "                                       write_meta_graph=False)\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format((epochs+1)* (c+1),f,h):\n",
    "                                                  (curr_pred, \n",
    "                                                   Train.result((epochs+1)*(c+1), f, h,valid_accuracy, accuracy, accuracy_, time.perf_counter() - start_time))})\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T17:37:14.778346Z",
     "start_time": "2017-06-23T17:37:14.718551Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "df_results = []\n",
    "past_scores = []\n",
    "\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "\n",
    "    def start_training():\n",
    "\n",
    "        global df_results\n",
    "        global past_scores\n",
    "        \n",
    "        Train.predictions = {}\n",
    "        Train.results = []\n",
    "        \n",
    "        features_arr = [1] #[4, 8, 16, 32]\n",
    "        hidden_layers_arr = [1, 3, 5]\n",
    "\n",
    "        epochs = [5]\n",
    "        lrs = [1e-2, 1e-2/2, 1e-2/4]\n",
    "\n",
    "        for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "            print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "            n = network(2,h,f)\n",
    "            n.build_layers()\n",
    "            Train.train(e, n, h,f, lrs)\n",
    "            \n",
    "        dict1 = {}\n",
    "        dict2 = []\n",
    "        for k, (v1, v2) in Train.predictions.items():\n",
    "            dict1.update({k: v1})\n",
    "            dict2.append(v2)\n",
    "            \n",
    "        Train.predictions = dict1\n",
    "        Train.results = dict2\n",
    "        df_results = pd.DataFrame(Train.results)\n",
    "        temp = df_results.set_index(['no_of_features', 'hidden_layers'])\n",
    "\n",
    "        if not os.path.isfile('dataset/tf_lstm_nsl_kdd-orig_all-.pkl'):\n",
    "            past_scores = temp\n",
    "        else:\n",
    "            past_scores = pd.read_pickle(\"dataset/tf_lstm_nsl_kdd-orig_all-.pkl\")\n",
    "\n",
    "        past_scores.append(temp).to_pickle(\"dataset/tf_lstm_nsl_kdd-orig_all-.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:04.406978Z",
     "start_time": "2017-06-23T17:37:14.780362Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.32261356711387634\n",
      "Step 1 | Training Loss: 0.016385 | Train Accuracy: 0.991270 | Test Accuracy: 0.773776, 0.569958\n",
      "Step 2 | Training Loss: 0.003571 | Train Accuracy: 0.998810 | Test Accuracy: 0.840268, 0.696118\n",
      "Step 3 | Training Loss: 0.001502 | Train Accuracy: 1.000000 | Test Accuracy: 0.863112, 0.739578\n",
      "Step 4 | Training Loss: 0.004050 | Train Accuracy: 1.000000 | Test Accuracy: 0.881388, 0.774346\n",
      "Step 5 | Training Loss: 0.001231 | Train Accuracy: 1.000000 | Test Accuracy: 0.894074, 0.798481\n",
      "Step 1 | Training Loss: 0.002052 | Train Accuracy: 0.999603 | Test Accuracy: 0.891324, 0.793249\n",
      "Step 2 | Training Loss: 0.001239 | Train Accuracy: 0.999603 | Test Accuracy: 0.896913, 0.803882\n",
      "Step 3 | Training Loss: 0.000982 | Train Accuracy: 0.999603 | Test Accuracy: 0.895937, 0.802025\n",
      "Step 4 | Training Loss: 0.001035 | Train Accuracy: 1.000000 | Test Accuracy: 0.897268, 0.804557\n",
      "Step 5 | Training Loss: 0.001145 | Train Accuracy: 1.000000 | Test Accuracy: 0.899264, 0.808354\n",
      "Step 1 | Training Loss: 0.001464 | Train Accuracy: 1.000000 | Test Accuracy: 0.898643, 0.807173\n",
      "Step 2 | Training Loss: 0.001832 | Train Accuracy: 1.000000 | Test Accuracy: 0.897977, 0.805907\n",
      "Step 3 | Training Loss: 0.001531 | Train Accuracy: 1.000000 | Test Accuracy: 0.899485, 0.808776\n",
      "Step 4 | Training Loss: 0.001457 | Train Accuracy: 1.000000 | Test Accuracy: 0.898953, 0.807764\n",
      "Step 5 | Training Loss: 0.000938 | Train Accuracy: 1.000000 | Test Accuracy: 0.898953, 0.807764\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.559927225112915\n",
      "Step 1 | Training Loss: 0.017922 | Train Accuracy: 0.979365 | Test Accuracy: 0.779941, 0.582532\n",
      "Step 2 | Training Loss: 0.018924 | Train Accuracy: 0.984524 | Test Accuracy: 0.824787, 0.667342\n",
      "Step 3 | Training Loss: 0.000674 | Train Accuracy: 1.000000 | Test Accuracy: 0.995609, 0.991646\n",
      "Step 4 | Training Loss: 0.000907 | Train Accuracy: 1.000000 | Test Accuracy: 0.998714, 0.997553\n",
      "Step 5 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 1 | Training Loss: 0.000968 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 2 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 3 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 4 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 4 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.998625, 0.997384\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.7863289713859558\n",
      "Step 1 | Training Loss: 0.026564 | Train Accuracy: 0.947222 | Test Accuracy: 0.772134, 0.568186\n",
      "Step 2 | Training Loss: 0.043492 | Train Accuracy: 0.969444 | Test Accuracy: 0.785708, 0.593924\n",
      "Step 3 | Training Loss: 0.009696 | Train Accuracy: 0.965079 | Test Accuracy: 0.756831, 0.539072\n",
      "Step 4 | Training Loss: 0.050644 | Train Accuracy: 0.965476 | Test Accuracy: 0.767876, 0.560084\n",
      "Step 5 | Training Loss: 0.018977 | Train Accuracy: 0.975397 | Test Accuracy: 0.778034, 0.582447\n",
      "Step 1 | Training Loss: 0.011449 | Train Accuracy: 0.976984 | Test Accuracy: 0.778877, 0.580506\n",
      "Step 2 | Training Loss: 0.017914 | Train Accuracy: 0.976190 | Test Accuracy: 0.779010, 0.580759\n",
      "Step 3 | Training Loss: 0.027341 | Train Accuracy: 0.984921 | Test Accuracy: 0.764061, 0.552321\n",
      "Step 4 | Training Loss: 0.009486 | Train Accuracy: 0.981349 | Test Accuracy: 0.765924, 0.555865\n",
      "Step 5 | Training Loss: 0.002418 | Train Accuracy: 0.980952 | Test Accuracy: 0.748581, 0.523207\n",
      "Step 1 | Training Loss: 0.040137 | Train Accuracy: 0.982143 | Test Accuracy: 0.749290, 0.524219\n",
      "Step 2 | Training Loss: 0.009283 | Train Accuracy: 0.987302 | Test Accuracy: 0.743923, 0.514093\n",
      "Step 3 | Training Loss: 0.023407 | Train Accuracy: 0.984127 | Test Accuracy: 0.739132, 0.505063\n",
      "Step 4 | Training Loss: 0.013160 | Train Accuracy: 0.981746 | Test Accuracy: 0.736027, 0.499072\n",
      "Step 5 | Training Loss: 0.039703 | Train Accuracy: 0.986905 | Test Accuracy: 0.738999, 0.504894\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.3755766451358795\n",
      "Step 1 | Training Loss: 0.007327 | Train Accuracy: 0.996032 | Test Accuracy: 0.798439, 0.617637\n",
      "Step 2 | Training Loss: 0.007452 | Train Accuracy: 0.998016 | Test Accuracy: 0.846655, 0.708270\n",
      "Step 3 | Training Loss: 0.002057 | Train Accuracy: 0.998810 | Test Accuracy: 0.864044, 0.741350\n",
      "Step 4 | Training Loss: 0.001243 | Train Accuracy: 0.999206 | Test Accuracy: 0.876996, 0.765992\n",
      "Step 5 | Training Loss: 0.001336 | Train Accuracy: 0.999603 | Test Accuracy: 0.882230, 0.775949\n",
      "Step 1 | Training Loss: 0.001425 | Train Accuracy: 0.999603 | Test Accuracy: 0.881565, 0.774684\n",
      "Step 2 | Training Loss: 0.001041 | Train Accuracy: 1.000000 | Test Accuracy: 0.890348, 0.791392\n",
      "Step 3 | Training Loss: 0.001788 | Train Accuracy: 1.000000 | Test Accuracy: 0.881609, 0.774768\n",
      "Step 4 | Training Loss: 0.005949 | Train Accuracy: 1.000000 | Test Accuracy: 0.880323, 0.772321\n",
      "Step 5 | Training Loss: 0.000956 | Train Accuracy: 1.000000 | Test Accuracy: 0.882363, 0.776203\n",
      "Step 1 | Training Loss: 0.000973 | Train Accuracy: 1.000000 | Test Accuracy: 0.880678, 0.772996\n",
      "Step 2 | Training Loss: 0.000682 | Train Accuracy: 1.000000 | Test Accuracy: 0.880944, 0.773502\n",
      "Step 3 | Training Loss: 0.001221 | Train Accuracy: 0.999603 | Test Accuracy: 0.881388, 0.774346\n",
      "Step 4 | Training Loss: 0.000969 | Train Accuracy: 1.000000 | Test Accuracy: 0.882275, 0.776034\n",
      "Step 5 | Training Loss: 0.000951 | Train Accuracy: 1.000000 | Test Accuracy: 0.880900, 0.773418\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.6488201022148132\n",
      "Step 1 | Training Loss: 0.011255 | Train Accuracy: 0.990476 | Test Accuracy: 0.917140, 0.843882\n",
      "Step 2 | Training Loss: 0.009192 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 3 | Training Loss: 0.000663 | Train Accuracy: 0.998016 | Test Accuracy: 0.999823, 0.999662\n",
      "Step 4 | Training Loss: 0.000652 | Train Accuracy: 1.000000 | Test Accuracy: 0.997693, 0.995612\n",
      "Step 5 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.997693, 0.995612\n",
      "Step 1 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.997427, 0.995106\n",
      "Step 2 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.997693, 0.995612\n",
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.997693, 0.995612\n",
      "Step 4 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.999556, 0.999156\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.998980, 0.998059\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.997871, 0.995949\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.997738, 0.995696\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.997738, 0.995696\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.997738, 0.995696\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.997738, 0.995696\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.2372693419456482\n",
      "Step 1 | Training Loss: 0.034761 | Train Accuracy: 0.962698 | Test Accuracy: 0.731547, 0.492321\n",
      "Step 2 | Training Loss: 0.043586 | Train Accuracy: 0.928968 | Test Accuracy: 0.748447, 0.527595\n",
      "Step 3 | Training Loss: 0.043813 | Train Accuracy: 0.963095 | Test Accuracy: 0.752085, 0.533165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.038528 | Train Accuracy: 0.959921 | Test Accuracy: 0.741927, 0.510464\n",
      "Step 5 | Training Loss: 0.031406 | Train Accuracy: 0.976984 | Test Accuracy: 0.757275, 0.540084\n",
      "Step 1 | Training Loss: 0.024576 | Train Accuracy: 0.977778 | Test Accuracy: 0.756388, 0.538143\n",
      "Step 2 | Training Loss: 0.016818 | Train Accuracy: 0.977778 | Test Accuracy: 0.757541, 0.540338\n",
      "Step 3 | Training Loss: 0.020849 | Train Accuracy: 0.979762 | Test Accuracy: 0.758295, 0.540675\n",
      "Step 4 | Training Loss: 0.026334 | Train Accuracy: 0.973413 | Test Accuracy: 0.756299, 0.537637\n",
      "Step 5 | Training Loss: 0.018600 | Train Accuracy: 0.978571 | Test Accuracy: 0.758472, 0.543038\n",
      "Step 1 | Training Loss: 0.004535 | Train Accuracy: 0.978968 | Test Accuracy: 0.758295, 0.542363\n",
      "Step 2 | Training Loss: 0.028874 | Train Accuracy: 0.983730 | Test Accuracy: 0.763219, 0.550127\n",
      "Step 3 | Training Loss: 0.010361 | Train Accuracy: 0.982143 | Test Accuracy: 0.762287, 0.549198\n",
      "Step 4 | Training Loss: 0.006997 | Train Accuracy: 0.981349 | Test Accuracy: 0.762287, 0.549198\n",
      "Step 5 | Training Loss: 0.015299 | Train Accuracy: 0.979762 | Test Accuracy: 0.762731, 0.550042\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.22085699439048767\n",
      "Step 1 | Training Loss: 0.013759 | Train Accuracy: 0.990873 | Test Accuracy: 0.776615, 0.575696\n",
      "Step 2 | Training Loss: 0.005293 | Train Accuracy: 0.999206 | Test Accuracy: 0.856769, 0.728186\n",
      "Step 3 | Training Loss: 0.003859 | Train Accuracy: 0.999206 | Test Accuracy: 0.879658, 0.771055\n",
      "Step 4 | Training Loss: 0.002229 | Train Accuracy: 1.000000 | Test Accuracy: 0.892033, 0.795274\n",
      "Step 5 | Training Loss: 0.002292 | Train Accuracy: 0.999603 | Test Accuracy: 0.898643, 0.807848\n",
      "Step 1 | Training Loss: 0.002769 | Train Accuracy: 0.998810 | Test Accuracy: 0.894739, 0.800000\n",
      "Step 2 | Training Loss: 0.007126 | Train Accuracy: 0.999603 | Test Accuracy: 0.897933, 0.806076\n",
      "Step 3 | Training Loss: 0.001984 | Train Accuracy: 0.998810 | Test Accuracy: 0.898199, 0.806582\n",
      "Step 4 | Training Loss: 0.001355 | Train Accuracy: 0.998413 | Test Accuracy: 0.900861, 0.812068\n",
      "Step 5 | Training Loss: 0.007245 | Train Accuracy: 1.000000 | Test Accuracy: 0.899352, 0.808523\n",
      "Step 1 | Training Loss: 0.001201 | Train Accuracy: 0.999206 | Test Accuracy: 0.899707, 0.809620\n",
      "Step 2 | Training Loss: 0.001996 | Train Accuracy: 0.999206 | Test Accuracy: 0.901925, 0.813671\n",
      "Step 3 | Training Loss: 0.001206 | Train Accuracy: 0.999603 | Test Accuracy: 0.900240, 0.810886\n",
      "Step 4 | Training Loss: 0.000753 | Train Accuracy: 1.000000 | Test Accuracy: 0.900506, 0.810717\n",
      "Step 5 | Training Loss: 0.001459 | Train Accuracy: 1.000000 | Test Accuracy: 0.901038, 0.812152\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.62211674451828\n",
      "Step 1 | Training Loss: 0.017722 | Train Accuracy: 0.975397 | Test Accuracy: 0.782647, 0.587679\n",
      "Step 2 | Training Loss: 0.000957 | Train Accuracy: 0.996429 | Test Accuracy: 0.979906, 0.962110\n",
      "Step 3 | Training Loss: 0.009436 | Train Accuracy: 0.996825 | Test Accuracy: 0.983321, 0.968608\n",
      "Step 4 | Training Loss: 0.001645 | Train Accuracy: 0.999206 | Test Accuracy: 0.976623, 0.955527\n",
      "Step 5 | Training Loss: 0.000652 | Train Accuracy: 0.997222 | Test Accuracy: 0.984608, 0.970717\n",
      "Step 1 | Training Loss: 0.000656 | Train Accuracy: 1.000000 | Test Accuracy: 0.981370, 0.964557\n",
      "Step 2 | Training Loss: 0.000652 | Train Accuracy: 0.999603 | Test Accuracy: 0.987136, 0.975527\n",
      "Step 3 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.983321, 0.968270\n",
      "Step 4 | Training Loss: 0.001141 | Train Accuracy: 1.000000 | Test Accuracy: 0.983321, 0.968270\n",
      "Step 5 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.983321, 0.968270\n",
      "Step 1 | Training Loss: 0.001141 | Train Accuracy: 1.000000 | Test Accuracy: 0.983321, 0.968270\n",
      "Step 2 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.983321, 0.968270\n",
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.983321, 0.968270\n",
      "Step 4 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.983321, 0.968270\n",
      "Step 5 | Training Loss: 0.000894 | Train Accuracy: 1.000000 | Test Accuracy: 0.983321, 0.968270\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.7481369972229004\n",
      "Step 1 | Training Loss: 0.042872 | Train Accuracy: 0.959921 | Test Accuracy: 0.774131, 0.572152\n",
      "Step 2 | Training Loss: 0.008223 | Train Accuracy: 0.971032 | Test Accuracy: 0.778345, 0.579662\n",
      "Step 3 | Training Loss: 0.011686 | Train Accuracy: 0.965476 | Test Accuracy: 0.796221, 0.614093\n",
      "Step 4 | Training Loss: 0.035020 | Train Accuracy: 0.978175 | Test Accuracy: 0.790410, 0.602869\n",
      "Step 5 | Training Loss: 0.054256 | Train Accuracy: 0.960317 | Test Accuracy: 0.796886, 0.618565\n",
      "Step 1 | Training Loss: 0.042240 | Train Accuracy: 0.955556 | Test Accuracy: 0.782470, 0.590549\n",
      "Step 2 | Training Loss: 0.039661 | Train Accuracy: 0.970635 | Test Accuracy: 0.762553, 0.553502\n",
      "Step 3 | Training Loss: 0.025790 | Train Accuracy: 0.968651 | Test Accuracy: 0.778877, 0.593080\n",
      "Step 4 | Training Loss: 0.012207 | Train Accuracy: 0.989286 | Test Accuracy: 0.792406, 0.605063\n",
      "Step 5 | Training Loss: 0.000741 | Train Accuracy: 0.990476 | Test Accuracy: 0.811435, 0.642616\n",
      "Step 1 | Training Loss: 0.001224 | Train Accuracy: 0.992857 | Test Accuracy: 0.806778, 0.633587\n",
      "Step 2 | Training Loss: 0.017760 | Train Accuracy: 0.992460 | Test Accuracy: 0.811125, 0.642869\n",
      "Step 3 | Training Loss: 0.000666 | Train Accuracy: 0.996429 | Test Accuracy: 0.809084, 0.637806\n",
      "Step 4 | Training Loss: 0.017772 | Train Accuracy: 0.996825 | Test Accuracy: 0.811036, 0.641519\n",
      "Step 5 | Training Loss: 0.000690 | Train Accuracy: 0.997619 | Test Accuracy: 0.809484, 0.638565\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.3876863121986389\n",
      "Step 1 | Training Loss: 0.007636 | Train Accuracy: 0.994444 | Test Accuracy: 0.786063, 0.594177\n",
      "Step 2 | Training Loss: 0.007485 | Train Accuracy: 0.998413 | Test Accuracy: 0.840756, 0.697046\n",
      "Step 3 | Training Loss: 0.003998 | Train Accuracy: 0.999603 | Test Accuracy: 0.840800, 0.697131\n",
      "Step 4 | Training Loss: 0.001544 | Train Accuracy: 1.000000 | Test Accuracy: 0.884759, 0.780760\n",
      "Step 5 | Training Loss: 0.002302 | Train Accuracy: 1.000000 | Test Accuracy: 0.873802, 0.759916\n",
      "Step 1 | Training Loss: 0.001268 | Train Accuracy: 1.000000 | Test Accuracy: 0.888618, 0.788101\n",
      "Step 2 | Training Loss: 0.001550 | Train Accuracy: 1.000000 | Test Accuracy: 0.891945, 0.794430\n",
      "Step 3 | Training Loss: 0.001360 | Train Accuracy: 1.000000 | Test Accuracy: 0.893852, 0.798059\n",
      "Step 4 | Training Loss: 0.001274 | Train Accuracy: 1.000000 | Test Accuracy: 0.895848, 0.801857\n",
      "Step 5 | Training Loss: 0.001243 | Train Accuracy: 1.000000 | Test Accuracy: 0.895449, 0.801097\n",
      "Step 1 | Training Loss: 0.001692 | Train Accuracy: 1.000000 | Test Accuracy: 0.896735, 0.803544\n",
      "Step 2 | Training Loss: 0.001752 | Train Accuracy: 1.000000 | Test Accuracy: 0.897401, 0.804810\n",
      "Step 3 | Training Loss: 0.000694 | Train Accuracy: 1.000000 | Test Accuracy: 0.895449, 0.801097\n",
      "Step 4 | Training Loss: 0.001282 | Train Accuracy: 1.000000 | Test Accuracy: 0.895538, 0.801266\n",
      "Step 5 | Training Loss: 0.000945 | Train Accuracy: 1.000000 | Test Accuracy: 0.894473, 0.799241\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.7714247703552246\n",
      "Step 1 | Training Loss: 0.036445 | Train Accuracy: 0.961905 | Test Accuracy: 0.771780, 0.567173\n",
      "Step 2 | Training Loss: 0.001960 | Train Accuracy: 0.997222 | Test Accuracy: 0.967441, 0.938312\n",
      "Step 3 | Training Loss: 0.000779 | Train Accuracy: 1.000000 | Test Accuracy: 0.998359, 0.996878\n",
      "Step 4 | Training Loss: 0.000653 | Train Accuracy: 0.999603 | Test Accuracy: 0.998492, 0.997131\n",
      "Step 5 | Training Loss: 0.000652 | Train Accuracy: 1.000000 | Test Accuracy: 0.985717, 0.972827\n",
      "Step 1 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.988112, 0.977384\n",
      "Step 2 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.994455, 0.989451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.994455, 0.989451\n",
      "Step 4 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.994455, 0.989451\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994455, 0.989451\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994455, 0.989451\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994455, 0.989451\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994411, 0.989367\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994411, 0.989367\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994411, 0.989367\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.2686302363872528\n",
      "Step 1 | Training Loss: 0.001330 | Train Accuracy: 0.964683 | Test Accuracy: 0.770360, 0.564641\n",
      "Step 2 | Training Loss: 0.031573 | Train Accuracy: 0.978571 | Test Accuracy: 0.781893, 0.586835\n",
      "Step 3 | Training Loss: 0.029833 | Train Accuracy: 0.971032 | Test Accuracy: 0.853132, 0.726076\n",
      "Step 4 | Training Loss: 0.008503 | Train Accuracy: 0.992460 | Test Accuracy: 0.897001, 0.804641\n",
      "Step 5 | Training Loss: 0.000979 | Train Accuracy: 0.999603 | Test Accuracy: 0.920245, 0.848270\n",
      "Step 1 | Training Loss: 0.001169 | Train Accuracy: 0.998810 | Test Accuracy: 0.935814, 0.877890\n",
      "Step 2 | Training Loss: 0.000651 | Train Accuracy: 0.999603 | Test Accuracy: 0.938165, 0.882363\n",
      "Step 3 | Training Loss: 0.001881 | Train Accuracy: 0.999603 | Test Accuracy: 0.939540, 0.884979\n",
      "Step 4 | Training Loss: 0.000897 | Train Accuracy: 0.999603 | Test Accuracy: 0.941758, 0.889198\n",
      "Step 5 | Training Loss: 0.000896 | Train Accuracy: 1.000000 | Test Accuracy: 0.941847, 0.889367\n",
      "Step 1 | Training Loss: 0.001141 | Train Accuracy: 0.999603 | Test Accuracy: 0.941758, 0.889198\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.941714, 0.889114\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.941625, 0.888945\n",
      "Step 4 | Training Loss: 0.001141 | Train Accuracy: 1.000000 | Test Accuracy: 0.941625, 0.888945\n",
      "Step 5 | Training Loss: 0.001633 | Train Accuracy: 1.000000 | Test Accuracy: 0.941625, 0.888945\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.6344925761222839\n",
      "Step 1 | Training Loss: 0.007703 | Train Accuracy: 0.996032 | Test Accuracy: 0.788769, 0.598903\n",
      "Step 2 | Training Loss: 0.004919 | Train Accuracy: 0.996825 | Test Accuracy: 0.806645, 0.632152\n",
      "Step 3 | Training Loss: 0.001508 | Train Accuracy: 0.997619 | Test Accuracy: 0.838538, 0.692827\n",
      "Step 4 | Training Loss: 0.005917 | Train Accuracy: 0.999206 | Test Accuracy: 0.890703, 0.792068\n",
      "Step 5 | Training Loss: 0.003990 | Train Accuracy: 1.000000 | Test Accuracy: 0.889328, 0.789451\n",
      "Step 1 | Training Loss: 0.002224 | Train Accuracy: 1.000000 | Test Accuracy: 0.896070, 0.802278\n",
      "Step 2 | Training Loss: 0.001698 | Train Accuracy: 1.000000 | Test Accuracy: 0.896159, 0.802447\n",
      "Step 3 | Training Loss: 0.002787 | Train Accuracy: 1.000000 | Test Accuracy: 0.896425, 0.802954\n",
      "Step 4 | Training Loss: 0.002573 | Train Accuracy: 1.000000 | Test Accuracy: 0.895094, 0.800422\n",
      "Step 5 | Training Loss: 0.002118 | Train Accuracy: 1.000000 | Test Accuracy: 0.895893, 0.801941\n",
      "Step 1 | Training Loss: 0.002969 | Train Accuracy: 1.000000 | Test Accuracy: 0.894695, 0.799662\n",
      "Step 2 | Training Loss: 0.003003 | Train Accuracy: 1.000000 | Test Accuracy: 0.893275, 0.796962\n",
      "Step 3 | Training Loss: 0.002655 | Train Accuracy: 1.000000 | Test Accuracy: 0.895804, 0.801772\n",
      "Step 4 | Training Loss: 0.006490 | Train Accuracy: 0.999603 | Test Accuracy: 0.894296, 0.798903\n",
      "Step 5 | Training Loss: 0.001220 | Train Accuracy: 1.000000 | Test Accuracy: 0.894961, 0.800169\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.36204755306243896\n",
      "Step 1 | Training Loss: 0.026323 | Train Accuracy: 0.976984 | Test Accuracy: 0.740774, 0.508186\n",
      "Step 2 | Training Loss: 0.016783 | Train Accuracy: 0.975000 | Test Accuracy: 0.759936, 0.544557\n",
      "Step 3 | Training Loss: 0.000660 | Train Accuracy: 0.999603 | Test Accuracy: 0.978531, 0.959156\n",
      "Step 4 | Training Loss: 0.000658 | Train Accuracy: 1.000000 | Test Accuracy: 0.989265, 0.979578\n",
      "Step 5 | Training Loss: 0.000650 | Train Accuracy: 0.999603 | Test Accuracy: 0.988334, 0.977806\n",
      "Step 1 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.988334, 0.977806\n",
      "Step 2 | Training Loss: 0.000974 | Train Accuracy: 0.999603 | Test Accuracy: 0.988334, 0.977806\n",
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.988334, 0.977806\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.988334, 0.977806\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.988290, 0.977722\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.988290, 0.977722\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.988290, 0.977722\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.988245, 0.977637\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.988245, 0.977637\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.988201, 0.977553\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.40227997303009033\n",
      "Step 1 | Training Loss: 0.019144 | Train Accuracy: 0.959921 | Test Accuracy: 0.780829, 0.585907\n",
      "Step 2 | Training Loss: 0.036113 | Train Accuracy: 0.973016 | Test Accuracy: 0.819863, 0.658987\n",
      "Step 3 | Training Loss: 0.009162 | Train Accuracy: 0.977778 | Test Accuracy: 0.793692, 0.608692\n",
      "Step 4 | Training Loss: 0.022193 | Train Accuracy: 0.981746 | Test Accuracy: 0.803007, 0.625232\n",
      "Step 5 | Training Loss: 0.025286 | Train Accuracy: 0.961905 | Test Accuracy: 0.810548, 0.642194\n",
      "Step 1 | Training Loss: 0.012703 | Train Accuracy: 0.995635 | Test Accuracy: 0.954312, 0.914177\n",
      "Step 2 | Training Loss: 0.003683 | Train Accuracy: 0.994841 | Test Accuracy: 0.956396, 0.918143\n",
      "Step 3 | Training Loss: 0.003371 | Train Accuracy: 0.996825 | Test Accuracy: 0.962163, 0.929114\n",
      "Step 4 | Training Loss: 0.002142 | Train Accuracy: 0.998810 | Test Accuracy: 0.963050, 0.930802\n",
      "Step 5 | Training Loss: 0.002374 | Train Accuracy: 0.998016 | Test Accuracy: 0.962961, 0.930633\n",
      "Step 1 | Training Loss: 0.012381 | Train Accuracy: 0.994841 | Test Accuracy: 0.962873, 0.930464\n",
      "Step 2 | Training Loss: 0.002373 | Train Accuracy: 0.998016 | Test Accuracy: 0.962873, 0.930464\n",
      "Step 3 | Training Loss: 0.003109 | Train Accuracy: 0.998413 | Test Accuracy: 0.962873, 0.930464\n",
      "Step 4 | Training Loss: 0.002620 | Train Accuracy: 0.998413 | Test Accuracy: 0.962873, 0.930464\n",
      "Step 5 | Training Loss: 0.001386 | Train Accuracy: 0.998810 | Test Accuracy: 0.962873, 0.930464\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.32039567828178406\n",
      "Step 1 | Training Loss: 0.004585 | Train Accuracy: 0.992460 | Test Accuracy: 0.785264, 0.591477\n",
      "Step 2 | Training Loss: 0.002542 | Train Accuracy: 0.999206 | Test Accuracy: 0.810326, 0.639156\n",
      "Step 3 | Training Loss: 0.003740 | Train Accuracy: 0.999603 | Test Accuracy: 0.844704, 0.704557\n",
      "Step 4 | Training Loss: 0.001847 | Train Accuracy: 1.000000 | Test Accuracy: 0.875044, 0.762278\n",
      "Step 5 | Training Loss: 0.001370 | Train Accuracy: 1.000000 | Test Accuracy: 0.895005, 0.800253\n",
      "Step 1 | Training Loss: 0.001233 | Train Accuracy: 1.000000 | Test Accuracy: 0.889416, 0.789620\n",
      "Step 2 | Training Loss: 0.001522 | Train Accuracy: 1.000000 | Test Accuracy: 0.884847, 0.780928\n",
      "Step 3 | Training Loss: 0.000708 | Train Accuracy: 1.000000 | Test Accuracy: 0.888130, 0.787173\n",
      "Step 4 | Training Loss: 0.001740 | Train Accuracy: 1.000000 | Test Accuracy: 0.889815, 0.790380\n",
      "Step 5 | Training Loss: 0.001432 | Train Accuracy: 1.000000 | Test Accuracy: 0.893275, 0.796962\n",
      "Step 1 | Training Loss: 0.001447 | Train Accuracy: 1.000000 | Test Accuracy: 0.893985, 0.798312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Training Loss: 0.001961 | Train Accuracy: 1.000000 | Test Accuracy: 0.890658, 0.791983\n",
      "Step 3 | Training Loss: 0.001042 | Train Accuracy: 1.000000 | Test Accuracy: 0.896824, 0.803713\n",
      "Step 4 | Training Loss: 0.001836 | Train Accuracy: 1.000000 | Test Accuracy: 0.894828, 0.799916\n",
      "Step 5 | Training Loss: 0.001475 | Train Accuracy: 1.000000 | Test Accuracy: 0.895094, 0.800422\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.5106014609336853\n",
      "Step 1 | Training Loss: 0.042527 | Train Accuracy: 0.972222 | Test Accuracy: 0.746274, 0.520169\n",
      "Step 2 | Training Loss: 0.000728 | Train Accuracy: 0.999603 | Test Accuracy: 0.999601, 0.999241\n",
      "Step 3 | Training Loss: 0.000664 | Train Accuracy: 1.000000 | Test Accuracy: 0.999956, 0.999916\n",
      "Step 4 | Training Loss: 0.000669 | Train Accuracy: 1.000000 | Test Accuracy: 0.999956, 0.999916\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 1 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 2 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 4 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.5434262156486511\n",
      "Step 1 | Training Loss: 0.027128 | Train Accuracy: 0.970238 | Test Accuracy: 0.793515, 0.610548\n",
      "Step 2 | Training Loss: 0.021065 | Train Accuracy: 0.965476 | Test Accuracy: 0.789611, 0.600844\n",
      "Step 3 | Training Loss: 0.009407 | Train Accuracy: 0.970238 | Test Accuracy: 0.797108, 0.615527\n",
      "Step 4 | Training Loss: 0.009408 | Train Accuracy: 0.987698 | Test Accuracy: 0.827670, 0.674008\n",
      "Step 5 | Training Loss: 0.000935 | Train Accuracy: 0.997222 | Test Accuracy: 0.950940, 0.906667\n",
      "Step 1 | Training Loss: 0.004560 | Train Accuracy: 0.996032 | Test Accuracy: 0.957638, 0.919662\n",
      "Step 2 | Training Loss: 0.001408 | Train Accuracy: 0.998016 | Test Accuracy: 0.956042, 0.916371\n",
      "Step 3 | Training Loss: 0.001653 | Train Accuracy: 0.998413 | Test Accuracy: 0.954489, 0.913418\n",
      "Step 4 | Training Loss: 0.001153 | Train Accuracy: 0.999603 | Test Accuracy: 0.951162, 0.907089\n",
      "Step 5 | Training Loss: 0.000915 | Train Accuracy: 0.999603 | Test Accuracy: 0.954578, 0.913586\n",
      "Step 1 | Training Loss: 0.000896 | Train Accuracy: 0.999603 | Test Accuracy: 0.954711, 0.913840\n",
      "Step 2 | Training Loss: 0.001142 | Train Accuracy: 0.999603 | Test Accuracy: 0.954666, 0.913755\n",
      "Step 3 | Training Loss: 0.001388 | Train Accuracy: 0.999603 | Test Accuracy: 0.954666, 0.913755\n",
      "Step 4 | Training Loss: 0.001393 | Train Accuracy: 0.998810 | Test Accuracy: 0.954666, 0.913755\n",
      "Step 5 | Training Loss: 0.001392 | Train Accuracy: 1.000000 | Test Accuracy: 0.954666, 0.913755\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.8322835564613342\n",
      "Step 1 | Training Loss: 0.005838 | Train Accuracy: 0.996032 | Test Accuracy: 0.797463, 0.614937\n",
      "Step 2 | Training Loss: 0.003041 | Train Accuracy: 0.998413 | Test Accuracy: 0.841909, 0.699241\n",
      "Step 3 | Training Loss: 0.002113 | Train Accuracy: 0.998810 | Test Accuracy: 0.833038, 0.682363\n",
      "Step 4 | Training Loss: 0.001211 | Train Accuracy: 1.000000 | Test Accuracy: 0.870875, 0.754346\n",
      "Step 5 | Training Loss: 0.001105 | Train Accuracy: 1.000000 | Test Accuracy: 0.875710, 0.763544\n",
      "Step 1 | Training Loss: 0.002017 | Train Accuracy: 1.000000 | Test Accuracy: 0.877573, 0.767089\n",
      "Step 2 | Training Loss: 0.000687 | Train Accuracy: 1.000000 | Test Accuracy: 0.873802, 0.759916\n",
      "Step 3 | Training Loss: 0.001137 | Train Accuracy: 1.000000 | Test Accuracy: 0.868834, 0.750464\n",
      "Step 4 | Training Loss: 0.001210 | Train Accuracy: 1.000000 | Test Accuracy: 0.873847, 0.760000\n",
      "Step 5 | Training Loss: 0.001216 | Train Accuracy: 1.000000 | Test Accuracy: 0.871274, 0.755105\n",
      "Step 1 | Training Loss: 0.002260 | Train Accuracy: 1.000000 | Test Accuracy: 0.874823, 0.761857\n",
      "Step 2 | Training Loss: 0.001965 | Train Accuracy: 1.000000 | Test Accuracy: 0.874290, 0.760844\n",
      "Step 3 | Training Loss: 0.001996 | Train Accuracy: 1.000000 | Test Accuracy: 0.872294, 0.757046\n",
      "Step 4 | Training Loss: 0.001249 | Train Accuracy: 1.000000 | Test Accuracy: 0.875843, 0.763797\n",
      "Step 5 | Training Loss: 0.001277 | Train Accuracy: 1.000000 | Test Accuracy: 0.872605, 0.757637\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.3923438489437103\n",
      "Step 1 | Training Loss: 0.017903 | Train Accuracy: 0.974603 | Test Accuracy: 0.729729, 0.487004\n",
      "Step 2 | Training Loss: 0.000718 | Train Accuracy: 0.998413 | Test Accuracy: 0.992326, 0.985654\n",
      "Step 3 | Training Loss: 0.011175 | Train Accuracy: 0.999603 | Test Accuracy: 0.993036, 0.986751\n",
      "Step 4 | Training Loss: 0.000652 | Train Accuracy: 1.000000 | Test Accuracy: 0.998359, 0.996878\n",
      "Step 5 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.999823, 0.999662\n",
      "Step 1 | Training Loss: 0.000650 | Train Accuracy: 0.999603 | Test Accuracy: 0.999823, 0.999662\n",
      "Step 2 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 3 | Training Loss: 0.000653 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 4 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 2 | Training Loss: 0.000659 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 4 | Training Loss: 0.000903 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.37486693263053894\n",
      "Step 1 | Training Loss: 0.018016 | Train Accuracy: 0.957540 | Test Accuracy: 0.802253, 0.627511\n",
      "Step 2 | Training Loss: 0.058537 | Train Accuracy: 0.966270 | Test Accuracy: 0.790809, 0.605063\n",
      "Step 3 | Training Loss: 0.036571 | Train Accuracy: 0.966667 | Test Accuracy: 0.822968, 0.666160\n",
      "Step 4 | Training Loss: 0.031813 | Train Accuracy: 0.973810 | Test Accuracy: 0.768453, 0.560759\n",
      "Step 5 | Training Loss: 0.018471 | Train Accuracy: 0.970635 | Test Accuracy: 0.780163, 0.583207\n",
      "Step 1 | Training Loss: 0.009487 | Train Accuracy: 0.983730 | Test Accuracy: 0.794358, 0.610380\n",
      "Step 2 | Training Loss: 0.018589 | Train Accuracy: 0.976190 | Test Accuracy: 0.768675, 0.561097\n",
      "Step 3 | Training Loss: 0.009108 | Train Accuracy: 0.987302 | Test Accuracy: 0.825630, 0.669367\n",
      "Step 4 | Training Loss: 0.000986 | Train Accuracy: 0.988095 | Test Accuracy: 0.871185, 0.754937\n",
      "Step 5 | Training Loss: 0.018108 | Train Accuracy: 0.990079 | Test Accuracy: 0.872161, 0.756793\n",
      "Step 1 | Training Loss: 0.001254 | Train Accuracy: 0.991270 | Test Accuracy: 0.896647, 0.803376\n",
      "Step 2 | Training Loss: 0.000906 | Train Accuracy: 0.993651 | Test Accuracy: 0.907425, 0.823882\n",
      "Step 3 | Training Loss: 0.000655 | Train Accuracy: 0.999603 | Test Accuracy: 0.967087, 0.937384\n",
      "Step 4 | Training Loss: 0.000898 | Train Accuracy: 1.000000 | Test Accuracy: 0.966466, 0.936203\n",
      "Step 5 | Training Loss: 0.001143 | Train Accuracy: 0.999603 | Test Accuracy: 0.966377, 0.936034\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Accuracy, before training: 0.7685858607292175\n",
      "Step 1 | Training Loss: 0.008558 | Train Accuracy: 0.995238 | Test Accuracy: 0.817113, 0.652067\n",
      "Step 2 | Training Loss: 0.004708 | Train Accuracy: 0.999603 | Test Accuracy: 0.825364, 0.667848\n",
      "Step 3 | Training Loss: 0.001624 | Train Accuracy: 0.999603 | Test Accuracy: 0.849760, 0.714177\n",
      "Step 4 | Training Loss: 0.001387 | Train Accuracy: 0.999603 | Test Accuracy: 0.849450, 0.713587\n",
      "Step 5 | Training Loss: 0.001592 | Train Accuracy: 1.000000 | Test Accuracy: 0.865596, 0.744304\n",
      "Step 1 | Training Loss: 0.006249 | Train Accuracy: 1.000000 | Test Accuracy: 0.894606, 0.799494\n",
      "Step 2 | Training Loss: 0.001059 | Train Accuracy: 1.000000 | Test Accuracy: 0.896026, 0.802194\n",
      "Step 3 | Training Loss: 0.001549 | Train Accuracy: 1.000000 | Test Accuracy: 0.897933, 0.805823\n",
      "Step 4 | Training Loss: 0.001581 | Train Accuracy: 1.000000 | Test Accuracy: 0.889505, 0.789789\n",
      "Step 5 | Training Loss: 0.001192 | Train Accuracy: 1.000000 | Test Accuracy: 0.887775, 0.786498\n",
      "Step 1 | Training Loss: 0.000931 | Train Accuracy: 1.000000 | Test Accuracy: 0.886134, 0.783376\n",
      "Step 2 | Training Loss: 0.000946 | Train Accuracy: 1.000000 | Test Accuracy: 0.894296, 0.798903\n",
      "Step 3 | Training Loss: 0.001315 | Train Accuracy: 1.000000 | Test Accuracy: 0.890703, 0.792068\n",
      "Step 4 | Training Loss: 0.000678 | Train Accuracy: 1.000000 | Test Accuracy: 0.888707, 0.788270\n",
      "Step 5 | Training Loss: 0.000689 | Train Accuracy: 1.000000 | Test Accuracy: 0.883251, 0.777890\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.29963627457618713\n",
      "Step 1 | Training Loss: 0.000719 | Train Accuracy: 0.999206 | Test Accuracy: 0.925878, 0.858987\n",
      "Step 2 | Training Loss: 0.000657 | Train Accuracy: 0.999603 | Test Accuracy: 0.965179, 0.933755\n",
      "Step 3 | Training Loss: 0.000651 | Train Accuracy: 0.999603 | Test Accuracy: 0.966421, 0.936118\n",
      "Step 4 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.962207, 0.928101\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 1 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 2 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.982168, 0.966076\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.3158268332481384\n",
      "Step 1 | Training Loss: 0.051544 | Train Accuracy: 0.942064 | Test Accuracy: 0.797640, 0.617215\n",
      "Step 2 | Training Loss: 0.017809 | Train Accuracy: 0.963889 | Test Accuracy: 0.829755, 0.678143\n",
      "Step 3 | Training Loss: 0.029185 | Train Accuracy: 0.977381 | Test Accuracy: 0.795866, 0.612827\n",
      "Step 4 | Training Loss: 0.010430 | Train Accuracy: 0.979762 | Test Accuracy: 0.836542, 0.690127\n",
      "Step 5 | Training Loss: 0.002410 | Train Accuracy: 0.997619 | Test Accuracy: 0.955199, 0.915865\n",
      "Step 1 | Training Loss: 0.002385 | Train Accuracy: 0.997619 | Test Accuracy: 0.950231, 0.906413\n",
      "Step 2 | Training Loss: 0.000662 | Train Accuracy: 0.999206 | Test Accuracy: 0.947702, 0.900506\n",
      "Step 3 | Training Loss: 0.000952 | Train Accuracy: 0.994048 | Test Accuracy: 0.970724, 0.947426\n",
      "Step 4 | Training Loss: 0.000655 | Train Accuracy: 0.999603 | Test Accuracy: 0.978265, 0.958650\n",
      "Step 5 | Training Loss: 0.000652 | Train Accuracy: 0.999603 | Test Accuracy: 0.978132, 0.958397\n",
      "Step 1 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.978132, 0.958397\n",
      "Step 2 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.978132, 0.958397\n",
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.978132, 0.958397\n",
      "Step 4 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.978132, 0.958397\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.978132, 0.958397\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.6453601717948914\n",
      "Step 1 | Training Loss: 0.001800 | Train Accuracy: 0.997222 | Test Accuracy: 0.795245, 0.611139\n",
      "Step 2 | Training Loss: 0.002879 | Train Accuracy: 0.998016 | Test Accuracy: 0.837030, 0.689958\n",
      "Step 3 | Training Loss: 0.001074 | Train Accuracy: 1.000000 | Test Accuracy: 0.862535, 0.738481\n",
      "Step 4 | Training Loss: 0.001120 | Train Accuracy: 1.000000 | Test Accuracy: 0.900994, 0.811646\n",
      "Step 5 | Training Loss: 0.001329 | Train Accuracy: 1.000000 | Test Accuracy: 0.897489, 0.804979\n",
      "Step 1 | Training Loss: 0.000722 | Train Accuracy: 1.000000 | Test Accuracy: 0.896380, 0.802869\n",
      "Step 2 | Training Loss: 0.000758 | Train Accuracy: 1.000000 | Test Accuracy: 0.893630, 0.797637\n",
      "Step 3 | Training Loss: 0.001992 | Train Accuracy: 1.000000 | Test Accuracy: 0.894695, 0.799662\n",
      "Step 4 | Training Loss: 0.001234 | Train Accuracy: 1.000000 | Test Accuracy: 0.894340, 0.798987\n",
      "Step 5 | Training Loss: 0.001225 | Train Accuracy: 1.000000 | Test Accuracy: 0.897223, 0.804473\n",
      "Step 1 | Training Loss: 0.000956 | Train Accuracy: 0.999603 | Test Accuracy: 0.894207, 0.798734\n",
      "Step 2 | Training Loss: 0.002546 | Train Accuracy: 1.000000 | Test Accuracy: 0.892344, 0.795190\n",
      "Step 3 | Training Loss: 0.001969 | Train Accuracy: 1.000000 | Test Accuracy: 0.892078, 0.794684\n",
      "Step 4 | Training Loss: 0.000919 | Train Accuracy: 1.000000 | Test Accuracy: 0.892832, 0.796118\n",
      "Step 5 | Training Loss: 0.001443 | Train Accuracy: 1.000000 | Test Accuracy: 0.892965, 0.796371\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.4498758018016815\n",
      "Step 1 | Training Loss: 0.071608 | Train Accuracy: 0.947222 | Test Accuracy: 0.771913, 0.570633\n",
      "Step 2 | Training Loss: 0.000947 | Train Accuracy: 0.998016 | Test Accuracy: 0.968550, 0.940169\n",
      "Step 3 | Training Loss: 0.000658 | Train Accuracy: 1.000000 | Test Accuracy: 0.980882, 0.963629\n",
      "Step 4 | Training Loss: 0.000658 | Train Accuracy: 1.000000 | Test Accuracy: 0.980039, 0.962025\n",
      "Step 5 | Training Loss: 0.000652 | Train Accuracy: 1.000000 | Test Accuracy: 0.997028, 0.994346\n",
      "Step 1 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 2 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 3 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 4 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 1 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999956, 0.999916\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999956, 0.999916\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999956, 0.999916\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.6715312004089355\n",
      "Step 1 | Training Loss: 0.051243 | Train Accuracy: 0.959127 | Test Accuracy: 0.751774, 0.534008\n",
      "Step 2 | Training Loss: 0.061208 | Train Accuracy: 0.963889 | Test Accuracy: 0.750089, 0.526160\n",
      "Step 3 | Training Loss: 0.018009 | Train Accuracy: 0.963492 | Test Accuracy: 0.748137, 0.522616\n",
      "Step 4 | Training Loss: 0.025120 | Train Accuracy: 0.964286 | Test Accuracy: 0.759626, 0.544810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | Training Loss: 0.005423 | Train Accuracy: 0.980952 | Test Accuracy: 0.772179, 0.567848\n",
      "Step 1 | Training Loss: 0.024905 | Train Accuracy: 0.980159 | Test Accuracy: 0.766501, 0.556878\n",
      "Step 2 | Training Loss: 0.000680 | Train Accuracy: 0.984127 | Test Accuracy: 0.773199, 0.568523\n",
      "Step 3 | Training Loss: 0.025375 | Train Accuracy: 0.983333 | Test Accuracy: 0.776038, 0.573924\n",
      "Step 4 | Training Loss: 0.026559 | Train Accuracy: 0.986905 | Test Accuracy: 0.777280, 0.577300\n",
      "Step 5 | Training Loss: 0.006672 | Train Accuracy: 0.982540 | Test Accuracy: 0.802165, 0.625316\n",
      "Step 1 | Training Loss: 0.000714 | Train Accuracy: 0.990079 | Test Accuracy: 0.785397, 0.592236\n",
      "Step 2 | Training Loss: 0.000701 | Train Accuracy: 0.989286 | Test Accuracy: 0.781982, 0.585823\n",
      "Step 3 | Training Loss: 0.009341 | Train Accuracy: 0.988889 | Test Accuracy: 0.792672, 0.605907\n",
      "Step 4 | Training Loss: 0.006135 | Train Accuracy: 0.991667 | Test Accuracy: 0.781272, 0.584388\n",
      "Step 5 | Training Loss: 0.011073 | Train Accuracy: 0.991667 | Test Accuracy: 0.790144, 0.600760\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.5601046681404114\n",
      "Step 1 | Training Loss: 0.007996 | Train Accuracy: 0.994841 | Test Accuracy: 0.801943, 0.623544\n",
      "Step 2 | Training Loss: 0.007254 | Train Accuracy: 0.999206 | Test Accuracy: 0.838760, 0.693586\n",
      "Step 3 | Training Loss: 0.001963 | Train Accuracy: 0.999206 | Test Accuracy: 0.852910, 0.720506\n",
      "Step 4 | Training Loss: 0.000779 | Train Accuracy: 0.999206 | Test Accuracy: 0.884759, 0.781097\n",
      "Step 5 | Training Loss: 0.001304 | Train Accuracy: 0.998810 | Test Accuracy: 0.886888, 0.785148\n",
      "Step 1 | Training Loss: 0.001147 | Train Accuracy: 0.999603 | Test Accuracy: 0.887775, 0.786835\n",
      "Step 2 | Training Loss: 0.001307 | Train Accuracy: 0.998413 | Test Accuracy: 0.887864, 0.787004\n",
      "Step 3 | Training Loss: 0.006571 | Train Accuracy: 0.999603 | Test Accuracy: 0.881121, 0.774177\n",
      "Step 4 | Training Loss: 0.000998 | Train Accuracy: 0.998413 | Test Accuracy: 0.882496, 0.776793\n",
      "Step 5 | Training Loss: 0.000981 | Train Accuracy: 0.999206 | Test Accuracy: 0.880767, 0.773502\n",
      "Step 1 | Training Loss: 0.001232 | Train Accuracy: 0.999603 | Test Accuracy: 0.882142, 0.776118\n",
      "Step 2 | Training Loss: 0.001245 | Train Accuracy: 0.998413 | Test Accuracy: 0.883117, 0.777975\n",
      "Step 3 | Training Loss: 0.001248 | Train Accuracy: 0.999206 | Test Accuracy: 0.882984, 0.777722\n",
      "Step 4 | Training Loss: 0.000772 | Train Accuracy: 0.999206 | Test Accuracy: 0.882896, 0.777553\n",
      "Step 5 | Training Loss: 0.001034 | Train Accuracy: 0.999603 | Test Accuracy: 0.883872, 0.779409\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.7260468602180481\n",
      "Step 1 | Training Loss: 0.049205 | Train Accuracy: 0.953175 | Test Accuracy: 0.723341, 0.475359\n",
      "Step 2 | Training Loss: 0.009636 | Train Accuracy: 0.976587 | Test Accuracy: 0.720458, 0.469367\n",
      "Step 3 | Training Loss: 0.008299 | Train Accuracy: 0.993254 | Test Accuracy: 0.895893, 0.803122\n",
      "Step 4 | Training Loss: 0.001423 | Train Accuracy: 0.996429 | Test Accuracy: 0.968506, 0.941181\n",
      "Step 5 | Training Loss: 0.000907 | Train Accuracy: 0.998810 | Test Accuracy: 0.968196, 0.940591\n",
      "Step 1 | Training Loss: 0.000655 | Train Accuracy: 0.998810 | Test Accuracy: 0.968196, 0.940591\n",
      "Step 2 | Training Loss: 0.001887 | Train Accuracy: 0.997222 | Test Accuracy: 0.968240, 0.940675\n",
      "Step 3 | Training Loss: 0.001388 | Train Accuracy: 0.997619 | Test Accuracy: 0.968284, 0.940759\n",
      "Step 4 | Training Loss: 0.000895 | Train Accuracy: 0.996825 | Test Accuracy: 0.968240, 0.940675\n",
      "Step 5 | Training Loss: 0.008373 | Train Accuracy: 0.996032 | Test Accuracy: 0.968284, 0.940759\n",
      "Step 1 | Training Loss: 0.000650 | Train Accuracy: 0.998413 | Test Accuracy: 0.968196, 0.940591\n",
      "Step 2 | Training Loss: 0.000895 | Train Accuracy: 0.998413 | Test Accuracy: 0.968062, 0.940338\n",
      "Step 3 | Training Loss: 0.000901 | Train Accuracy: 0.998016 | Test Accuracy: 0.968151, 0.940506\n",
      "Step 4 | Training Loss: 0.000655 | Train Accuracy: 0.997222 | Test Accuracy: 0.968151, 0.940506\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 0.999206 | Test Accuracy: 0.967885, 0.940000\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.4427785575389862\n",
      "Step 1 | Training Loss: 0.020594 | Train Accuracy: 0.969841 | Test Accuracy: 0.770582, 0.565401\n",
      "Step 2 | Training Loss: 0.028860 | Train Accuracy: 0.969841 | Test Accuracy: 0.818045, 0.655696\n",
      "Step 3 | Training Loss: 0.017649 | Train Accuracy: 0.972222 | Test Accuracy: 0.795289, 0.611983\n",
      "Step 4 | Training Loss: 0.024541 | Train Accuracy: 0.971825 | Test Accuracy: 0.755456, 0.535949\n",
      "Step 5 | Training Loss: 0.014405 | Train Accuracy: 0.982143 | Test Accuracy: 0.779986, 0.582785\n",
      "Step 1 | Training Loss: 0.030694 | Train Accuracy: 0.987302 | Test Accuracy: 0.806290, 0.632658\n",
      "Step 2 | Training Loss: 0.005424 | Train Accuracy: 0.988889 | Test Accuracy: 0.815339, 0.649873\n",
      "Step 3 | Training Loss: 0.012696 | Train Accuracy: 0.986111 | Test Accuracy: 0.819597, 0.657975\n",
      "Step 4 | Training Loss: 0.011572 | Train Accuracy: 0.987698 | Test Accuracy: 0.841998, 0.700591\n",
      "Step 5 | Training Loss: 0.021956 | Train Accuracy: 0.983730 | Test Accuracy: 0.918027, 0.846582\n",
      "Step 1 | Training Loss: 0.016460 | Train Accuracy: 0.994444 | Test Accuracy: 0.913990, 0.837553\n",
      "Step 2 | Training Loss: 0.005861 | Train Accuracy: 0.992857 | Test Accuracy: 0.914567, 0.838650\n",
      "Step 3 | Training Loss: 0.006159 | Train Accuracy: 1.000000 | Test Accuracy: 0.955953, 0.916203\n",
      "Step 4 | Training Loss: 0.005859 | Train Accuracy: 1.000000 | Test Accuracy: 0.964292, 0.932068\n",
      "Step 5 | Training Loss: 0.004119 | Train Accuracy: 0.999603 | Test Accuracy: 0.960522, 0.924895\n",
      "Current Layer Attributes - epochs:5 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.5761178135871887\n",
      "Step 1 | Training Loss: 0.013193 | Train Accuracy: 0.991270 | Test Accuracy: 0.780119, 0.581688\n",
      "Step 2 | Training Loss: 0.006667 | Train Accuracy: 0.998016 | Test Accuracy: 0.819597, 0.656793\n",
      "Step 3 | Training Loss: 0.003036 | Train Accuracy: 0.999603 | Test Accuracy: 0.859164, 0.732068\n",
      "Step 4 | Training Loss: 0.001329 | Train Accuracy: 1.000000 | Test Accuracy: 0.878815, 0.769451\n",
      "Step 5 | Training Loss: 0.001846 | Train Accuracy: 1.000000 | Test Accuracy: 0.897711, 0.805401\n",
      "Step 1 | Training Loss: 0.001792 | Train Accuracy: 1.000000 | Test Accuracy: 0.896292, 0.802700\n",
      "Step 2 | Training Loss: 0.001215 | Train Accuracy: 1.000000 | Test Accuracy: 0.888130, 0.787173\n",
      "Step 3 | Training Loss: 0.000728 | Train Accuracy: 1.000000 | Test Accuracy: 0.894872, 0.800000\n",
      "Step 4 | Training Loss: 0.001294 | Train Accuracy: 1.000000 | Test Accuracy: 0.889328, 0.789451\n",
      "Step 5 | Training Loss: 0.001264 | Train Accuracy: 0.999603 | Test Accuracy: 0.899663, 0.809114\n",
      "Step 1 | Training Loss: 0.000742 | Train Accuracy: 1.000000 | Test Accuracy: 0.895538, 0.801266\n",
      "Step 2 | Training Loss: 0.001339 | Train Accuracy: 1.000000 | Test Accuracy: 0.896070, 0.802278\n",
      "Step 3 | Training Loss: 0.001175 | Train Accuracy: 1.000000 | Test Accuracy: 0.892787, 0.796034\n",
      "Step 4 | Training Loss: 0.000667 | Train Accuracy: 1.000000 | Test Accuracy: 0.887154, 0.785316\n",
      "Step 5 | Training Loss: 0.001178 | Train Accuracy: 1.000000 | Test Accuracy: 0.896469, 0.803038\n",
      "Current Layer Attributes - epochs:5 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.4353708326816559\n",
      "Step 1 | Training Loss: 0.012035 | Train Accuracy: 0.994841 | Test Accuracy: 0.981503, 0.965992\n",
      "Step 2 | Training Loss: 0.000683 | Train Accuracy: 1.000000 | Test Accuracy: 0.998359, 0.996878\n",
      "Step 3 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.998758, 0.997637\n",
      "Step 4 | Training Loss: 0.000653 | Train Accuracy: 0.999603 | Test Accuracy: 0.998935, 0.997975\n",
      "Step 5 | Training Loss: 0.000653 | Train Accuracy: 1.000000 | Test Accuracy: 0.998536, 0.997215\n",
      "Step 1 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.998403, 0.996962\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998270, 0.996709\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998226, 0.996624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998181, 0.996540\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998137, 0.996456\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998137, 0.996456\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.998137, 0.996456\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998137, 0.996456\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998137, 0.996456\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998137, 0.996456\n",
      "Current Layer Attributes - epochs:5 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.2801632285118103\n",
      "Step 1 | Training Loss: 0.068687 | Train Accuracy: 0.948810 | Test Accuracy: 0.820884, 0.665485\n",
      "Step 2 | Training Loss: 0.048667 | Train Accuracy: 0.976984 | Test Accuracy: 0.792850, 0.607848\n",
      "Step 3 | Training Loss: 0.069508 | Train Accuracy: 0.915079 | Test Accuracy: 0.753726, 0.536878\n",
      "Step 4 | Training Loss: 0.023807 | Train Accuracy: 0.970635 | Test Accuracy: 0.743790, 0.515949\n",
      "Step 5 | Training Loss: 0.000908 | Train Accuracy: 0.997222 | Test Accuracy: 0.916785, 0.841688\n",
      "Step 1 | Training Loss: 0.001268 | Train Accuracy: 0.992460 | Test Accuracy: 0.913636, 0.835696\n",
      "Step 2 | Training Loss: 0.000656 | Train Accuracy: 0.990873 | Test Accuracy: 0.934750, 0.876962\n",
      "Step 3 | Training Loss: 0.016182 | Train Accuracy: 0.986111 | Test Accuracy: 0.875976, 0.768523\n",
      "Step 4 | Training Loss: 0.045985 | Train Accuracy: 0.951984 | Test Accuracy: 0.812722, 0.646920\n",
      "Step 5 | Training Loss: 0.017921 | Train Accuracy: 0.975397 | Test Accuracy: 0.802786, 0.624894\n",
      "Step 1 | Training Loss: 0.010075 | Train Accuracy: 0.980159 | Test Accuracy: 0.796443, 0.613249\n",
      "Step 2 | Training Loss: 0.018223 | Train Accuracy: 0.979365 | Test Accuracy: 0.791652, 0.603629\n",
      "Step 3 | Training Loss: 0.001667 | Train Accuracy: 0.980556 | Test Accuracy: 0.802919, 0.625485\n",
      "Step 4 | Training Loss: 0.025231 | Train Accuracy: 0.983730 | Test Accuracy: 0.824831, 0.666835\n",
      "Step 5 | Training Loss: 0.007898 | Train Accuracy: 0.984127 | Test Accuracy: 0.845813, 0.706667\n",
      "2min 20s  452 ms per loop (mean  std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10\n",
    "\n",
    "Hyperparameters.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T20:12:38.742950Z",
     "start_time": "2017-06-16T20:12:38.705898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T20:12:38.748800Z",
     "start_time": "2017-06-16T20:12:38.744607Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:04.422980Z",
     "start_time": "2017-06-23T18:03:04.408915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.997975</td>\n",
       "      <td>12.709743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  \\\n",
       "2      6               1              3     0.999603    0.998935   \n",
       "\n",
       "   test_score_20  time_taken  \n",
       "2       0.997975   12.709743  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df_results.groupby(by=['no_of_features'])\n",
    "idx = g['test_score'].transform(max) == df_results['test_score']\n",
    "df_results[idx].sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:04.496474Z",
     "start_time": "2017-06-23T18:03:04.424361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.997975</td>\n",
       "      <td>12.709743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>0.934750</td>\n",
       "      <td>0.876962</td>\n",
       "      <td>34.243220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.916785</td>\n",
       "      <td>0.841688</td>\n",
       "      <td>24.783175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.899663</td>\n",
       "      <td>0.809114</td>\n",
       "      <td>11.786242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897711</td>\n",
       "      <td>0.805401</td>\n",
       "      <td>5.986903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  \\\n",
       "2      6               1              3     0.999603    0.998935   \n",
       "4     12               1              5     0.990873    0.934750   \n",
       "3      6               1              5     0.997222    0.916785   \n",
       "1     12               1              1     0.999603    0.899663   \n",
       "0      6               1              1     1.000000    0.897711   \n",
       "\n",
       "   test_score_20  time_taken  \n",
       "2       0.997975   12.709743  \n",
       "4       0.876962   34.243220  \n",
       "3       0.841688   24.783175  \n",
       "1       0.809114   11.786242  \n",
       "0       0.805401    5.986903  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:04.508769Z",
     "start_time": "2017-06-23T18:03:04.497833Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_lstm_nsl_kdd_predictions-.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_lstm_nsl_kdd_scores-.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:04.569116Z",
     "start_time": "2017-06-23T18:03:04.510161Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = False,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:05.361485Z",
     "start_time": "2017-06-23T18:03:04.570759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 9711     0]\n",
      " [    0 12833]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8sdBzczM8ud/w/cOukuB/Y7FQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c589ab8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:05.614738Z",
     "start_time": "2017-06-23T18:03:05.363240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[2152    0]\n",
      " [   0 9698]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGgCAYAAAAtsfn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c58d4d780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value_, pred_value = Train.pred_value_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:05.653911Z",
     "start_time": "2017-06-23T18:03:05.616158Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.5 GB\n",
    "pd.Series(Train.pred_value).to_csv('LSTM_prediction_values-.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T18:03:05.681206Z",
     "start_time": "2017-06-23T18:03:05.655634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"35\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.798481</td>\n",
       "      <td>5.780286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899264</td>\n",
       "      <td>0.808354</td>\n",
       "      <td>11.488336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899485</td>\n",
       "      <td>0.808776</td>\n",
       "      <td>14.904817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998714</td>\n",
       "      <td>0.997553</td>\n",
       "      <td>12.624567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.969444</td>\n",
       "      <td>0.785708</td>\n",
       "      <td>0.593924</td>\n",
       "      <td>10.714801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894074</td>\n",
       "      <td>0.798481</td>\n",
       "      <td>5.780286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899264</td>\n",
       "      <td>0.808354</td>\n",
       "      <td>11.488336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899485</td>\n",
       "      <td>0.808776</td>\n",
       "      <td>14.904817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998714</td>\n",
       "      <td>0.997553</td>\n",
       "      <td>12.624567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.969444</td>\n",
       "      <td>0.785708</td>\n",
       "      <td>0.593924</td>\n",
       "      <td>10.714801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.882230</td>\n",
       "      <td>0.775949</td>\n",
       "      <td>5.969323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890348</td>\n",
       "      <td>0.791392</td>\n",
       "      <td>8.273357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.571577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.976984</td>\n",
       "      <td>0.757275</td>\n",
       "      <td>0.540084</td>\n",
       "      <td>24.895278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.758472</td>\n",
       "      <td>0.543038</td>\n",
       "      <td>48.575404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>0.983730</td>\n",
       "      <td>0.763219</td>\n",
       "      <td>0.550127</td>\n",
       "      <td>58.080909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.898643</td>\n",
       "      <td>0.807848</td>\n",
       "      <td>6.005653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.967087</td>\n",
       "      <td>0.937384</td>\n",
       "      <td>63.636937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865596</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>5.999650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897933</td>\n",
       "      <td>0.805823</td>\n",
       "      <td>9.473221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982168</td>\n",
       "      <td>0.966076</td>\n",
       "      <td>15.410883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.997619</td>\n",
       "      <td>0.955199</td>\n",
       "      <td>0.915865</td>\n",
       "      <td>24.915514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.978265</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>43.918620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900994</td>\n",
       "      <td>0.811646</td>\n",
       "      <td>4.805481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997028</td>\n",
       "      <td>0.994346</td>\n",
       "      <td>15.412469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.365605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.772179</td>\n",
       "      <td>0.567848</td>\n",
       "      <td>24.580175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0.982540</td>\n",
       "      <td>0.802165</td>\n",
       "      <td>0.625316</td>\n",
       "      <td>48.647938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.998810</td>\n",
       "      <td>0.886888</td>\n",
       "      <td>0.785148</td>\n",
       "      <td>5.964838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>0.887864</td>\n",
       "      <td>0.787004</td>\n",
       "      <td>8.282625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.968506</td>\n",
       "      <td>0.941181</td>\n",
       "      <td>12.583142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.969841</td>\n",
       "      <td>0.818045</td>\n",
       "      <td>0.655696</td>\n",
       "      <td>10.807881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0.983730</td>\n",
       "      <td>0.918027</td>\n",
       "      <td>0.846582</td>\n",
       "      <td>48.959744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964292</td>\n",
       "      <td>0.932068</td>\n",
       "      <td>67.910097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              epoch  train_score  test_score  test_score_20  \\\n",
       "no_of_features hidden_layers                                                  \n",
       "1              1                  6     1.000000    0.894074       0.798481   \n",
       "               1                 12     1.000000    0.899264       0.808354   \n",
       "               1                 18     1.000000    0.899485       0.808776   \n",
       "               3                  6     1.000000    0.998714       0.997553   \n",
       "               5                  6     0.969444    0.785708       0.593924   \n",
       "               1                  6     1.000000    0.894074       0.798481   \n",
       "               1                 12     1.000000    0.899264       0.808354   \n",
       "               1                 18     1.000000    0.899485       0.808776   \n",
       "               3                  6     1.000000    0.998714       0.997553   \n",
       "               5                  6     0.969444    0.785708       0.593924   \n",
       "               1                  6     0.999603    0.882230       0.775949   \n",
       "               1                 12     1.000000    0.890348       0.791392   \n",
       "               3                  6     1.000000    1.000000       1.000000   \n",
       "               5                  6     0.976984    0.757275       0.540084   \n",
       "               5                 12     0.978571    0.758472       0.543038   \n",
       "               5                 18     0.983730    0.763219       0.550127   \n",
       "               1                  6     0.999603    0.898643       0.807848   \n",
       "...                             ...          ...         ...            ...   \n",
       "               5                 18     0.999603    0.967087       0.937384   \n",
       "               1                  6     1.000000    0.865596       0.744304   \n",
       "               1                 12     1.000000    0.897933       0.805823   \n",
       "               3                  6     1.000000    0.982168       0.966076   \n",
       "               5                  6     0.997619    0.955199       0.915865   \n",
       "               5                 12     0.999603    0.978265       0.958650   \n",
       "               1                  6     1.000000    0.900994       0.811646   \n",
       "               3                  6     1.000000    0.997028       0.994346   \n",
       "               3                 12     1.000000    1.000000       1.000000   \n",
       "               5                  6     0.980952    0.772179       0.567848   \n",
       "               5                 12     0.982540    0.802165       0.625316   \n",
       "               1                  6     0.998810    0.886888       0.785148   \n",
       "               1                 12     0.998413    0.887864       0.787004   \n",
       "               3                  6     0.996429    0.968506       0.941181   \n",
       "               5                  6     0.969841    0.818045       0.655696   \n",
       "               5                 12     0.983730    0.918027       0.846582   \n",
       "               5                 18     1.000000    0.964292       0.932068   \n",
       "\n",
       "                              time_taken  \n",
       "no_of_features hidden_layers              \n",
       "1              1                5.780286  \n",
       "               1               11.488336  \n",
       "               1               14.904817  \n",
       "               3               12.624567  \n",
       "               5               10.714801  \n",
       "               1                5.780286  \n",
       "               1               11.488336  \n",
       "               1               14.904817  \n",
       "               3               12.624567  \n",
       "               5               10.714801  \n",
       "               1                5.969323  \n",
       "               1                8.273357  \n",
       "               3                6.571577  \n",
       "               5               24.895278  \n",
       "               5               48.575404  \n",
       "               5               58.080909  \n",
       "               1                6.005653  \n",
       "...                                  ...  \n",
       "               5               63.636937  \n",
       "               1                5.999650  \n",
       "               1                9.473221  \n",
       "               3               15.410883  \n",
       "               5               24.915514  \n",
       "               5               43.918620  \n",
       "               1                4.805481  \n",
       "               3               15.412469  \n",
       "               3               18.365605  \n",
       "               5               24.580175  \n",
       "               5               48.647938  \n",
       "               1                5.964838  \n",
       "               1                8.282625  \n",
       "               3               12.583142  \n",
       "               5               10.807881  \n",
       "               5               48.959744  \n",
       "               5               67.910097  \n",
       "\n",
       "[62 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T21:27:17.508311Z",
     "start_time": "2017-06-23T21:27:17.463375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>10.560000</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>0.892367</td>\n",
       "      <td>0.795325</td>\n",
       "      <td>8.895777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.993172</td>\n",
       "      <td>0.987089</td>\n",
       "      <td>14.476304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.913043</td>\n",
       "      <td>0.985404</td>\n",
       "      <td>0.864464</td>\n",
       "      <td>0.743409</td>\n",
       "      <td>35.142935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  epoch  train_score  test_score  \\\n",
       "no_of_features hidden_layers                                       \n",
       "1              1              10.560000     0.999730    0.892367   \n",
       "               3               7.285714     0.999490    0.993172   \n",
       "               5               9.913043     0.985404    0.864464   \n",
       "\n",
       "                              test_score_20  time_taken  \n",
       "no_of_features hidden_layers                             \n",
       "1              1                   0.795325    8.895777  \n",
       "               3                   0.987089   14.476304  \n",
       "               5                   0.743409   35.142935  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgb = past_scores.groupby(by=['no_of_features', 'hidden_layers'])\n",
    "pgb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T21:27:23.285234Z",
     "start_time": "2017-06-23T21:27:23.255659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>4.673329</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>3.599225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.554892</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>0.017979</td>\n",
       "      <td>4.153131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.284359</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.082740</td>\n",
       "      <td>0.156682</td>\n",
       "      <td>18.024586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 epoch  train_score  test_score  \\\n",
       "no_of_features hidden_layers                                      \n",
       "1              1              4.673329     0.000509    0.009179   \n",
       "               3              2.554892     0.001148    0.009564   \n",
       "               5              4.284359     0.012963    0.082740   \n",
       "\n",
       "                              test_score_20  time_taken  \n",
       "no_of_features hidden_layers                             \n",
       "1              1                   0.017505    3.599225  \n",
       "               3                   0.017979    4.153131  \n",
       "               5                   0.156682   18.024586  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgb.std()"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
